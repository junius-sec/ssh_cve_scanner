"""
Remote Scan API Router

ì›ê²© í˜¸ìŠ¤íŠ¸ ìŠ¤ìº”ì„ ìœ„í•œ ìƒˆë¡œìš´ API ì—”ë“œí¬ì¸íŠ¸
ê¸°ì¡´ /api/scan/{host_id}ì™€ í˜¸í™˜ì„± ìœ ì§€í•˜ë©´ì„œ í™•ì¥
"""

from fastapi import APIRouter, Depends, HTTPException, Query, BackgroundTasks
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, text
from typing import List, Optional
from pydantic import BaseModel, Field
from datetime import datetime, timezone, timedelta
import json
import asyncio
import logging

logger = logging.getLogger(__name__)

# KST timezone
KST = timezone(timedelta(hours=9))

from ..models.database import get_db
from ..models.schemas import Host, ScanJob, AssetSnapshot, AuditLog, ScanHistory, Finding, Package, CVE
from ..services.job_runner import (
    JobRunner, ScanPreset, ScanConfig, 
    get_job_runner, init_job_runner
)
from ..services.remote_scanner import RemoteScanner

router = APIRouter(prefix="/api/remote", tags=["remote-scan"])


# === Pydantic Models ===

class HostCreateRequest(BaseModel):
    """í˜¸ìŠ¤íŠ¸ ë“±ë¡ ìš”ì²­"""
    hostname: str
    ip_address: str
    zone: str = "default"
    os_type: str = "linux"
    ssh_port: int = 22
    ssh_username: str = "root"
    auth_method: str = "key"  # key, password
    ssh_key_path: Optional[str] = None
    ssh_password: Optional[str] = None  # ë¹„ë°€ë²ˆí˜¸ ì¸ì¦ìš©
    tags: Optional[str] = None
    owner: Optional[str] = None
    description: Optional[str] = None
    is_allowed: bool = True  # allowlist ë“±ë¡ ì—¬ë¶€


class HostResponse(BaseModel):
    """í˜¸ìŠ¤íŠ¸ ì‘ë‹µ"""
    id: int
    hostname: str
    ip_address: str
    zone: Optional[str] = "default"
    os_type: Optional[str] = "linux"
    os_version: Optional[str] = None
    ssh_port: Optional[int] = 22
    ssh_username: Optional[str] = "root"
    auth_method: Optional[str] = "key"
    is_allowed: Optional[bool] = True
    tags: Optional[str] = None
    owner: Optional[str] = None
    last_scan: Optional[datetime] = None
    last_discovery: Optional[datetime] = None
    distro_id: Optional[str] = None
    pkg_manager: Optional[str] = None
    arch: Optional[str] = None
    status: Optional[str] = "unknown"

    class Config:
        from_attributes = True


class ScanRequest(BaseModel):
    """ìŠ¤ìº” ìš”ì²­"""
    host_id: Optional[int] = None  # bodyì—ì„œë„ ë°›ì„ ìˆ˜ ìˆë„ë¡
    preset: str = "standard"  # fast, standard, deep
    categories: List[str] = ["all"]
    filter_patched: bool = True
    filter_old_cve: bool = True
    cve_years: Optional[int] = None  # CVE ê²€ìƒ‰ ì‹œì‘ ë…„ë„ (ì˜ˆ: 2024), None = ì „ì²´
    initiated_by: str = "api"


class ScanJobResponse(BaseModel):
    """ìŠ¤ìº” ì‘ì—… ì‘ë‹µ"""
    id: int  # job_id
    host_id: int
    status: Optional[str] = "pending"
    preset: Optional[str] = "standard"
    current_phase: Optional[str] = None  # phase
    progress_percent: Optional[int] = 0  # progress
    progress_message: Optional[str] = None  # message
    created_at: Optional[datetime] = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    finished_at: Optional[datetime] = None  # alias for completed_at (JS í˜¸í™˜ì„±)
    packages_found: Optional[int] = 0
    cves_found: Optional[int] = 0
    findings_count: Optional[int] = 0  # for history display
    high_risk_count: Optional[int] = 0
    error_message: Optional[str] = None

    class Config:
        from_attributes = True


class SnapshotResponse(BaseModel):
    """ìì‚° ìŠ¤ëƒ…ìƒ· ì‘ë‹µ"""
    id: int
    host_id: int
    created_at: datetime
    distro_id: Optional[str]
    pkg_manager: Optional[str]
    arch: Optional[str]
    kernel_version: Optional[str]
    is_busybox: bool
    has_systemd: bool
    packages_hash: Optional[str]
    collector_mode: Optional[str]
    confidence_discovery: Optional[str]

    class Config:
        from_attributes = True


# === Host Management Endpoints ===

@router.post("/hosts", response_model=HostResponse)
async def create_remote_host(
    request: HostCreateRequest,
    session: AsyncSession = Depends(get_db)
):
    """
    ì›ê²© í˜¸ìŠ¤íŠ¸ ë“±ë¡ (allowlistì— ì¶”ê°€)
    
    ìŠ¤ìº” ëŒ€ìƒ í˜¸ìŠ¤íŠ¸ë¥¼ ë“±ë¡í•©ë‹ˆë‹¤. is_allowed=Trueì—¬ì•¼ ìŠ¤ìº” ê°€ëŠ¥í•©ë‹ˆë‹¤.
    """
    # ì¤‘ë³µ ì²´í¬
    existing = await session.execute(
        select(Host).where(Host.hostname == request.hostname)
    )
    if existing.scalar_one_or_none():
        raise HTTPException(status_code=400, detail="Host already exists")
    
    # í˜¸ìŠ¤íŠ¸ ìƒì„±
    host = Host(
        hostname=request.hostname,
        ip_address=request.ip_address,
        zone=request.zone,
        os_type=request.os_type,
        ssh_port=request.ssh_port,
        ssh_username=request.ssh_username,
        auth_method=request.auth_method,
        ssh_key_path=request.ssh_key_path,
        ssh_password=request.ssh_password,  # ë¹„ë°€ë²ˆí˜¸ ì¶”ê°€
        tags=request.tags,
        owner=request.owner,
        description=request.description,
        is_allowed=request.is_allowed,
    )
    session.add(host)
    
    # Audit log
    audit = AuditLog(
        actor=request.owner or "system",
        action="host_add",
        target_type="host",
        target_name=request.hostname,
        details=json.dumps(request.dict()),
        result="success"
    )
    session.add(audit)
    
    await session.commit()
    await session.refresh(host)
    
    return host


@router.get("/hosts", response_model=List[HostResponse])
async def list_remote_hosts(
    allowed_only: bool = Query(True, description="allowlist í˜¸ìŠ¤íŠ¸ë§Œ ì¡°íšŒ"),
    session: AsyncSession = Depends(get_db)
):
    """ì›ê²© í˜¸ìŠ¤íŠ¸ ëª©ë¡ ì¡°íšŒ"""
    query = select(Host)
    if allowed_only:
        query = query.where(Host.is_allowed == True)
    
    result = await session.execute(query)
    return result.scalars().all()


@router.get("/hosts/{host_id}", response_model=HostResponse)
async def get_remote_host(
    host_id: int,
    session: AsyncSession = Depends(get_db)
):
    """ì›ê²© í˜¸ìŠ¤íŠ¸ ìƒì„¸ ì¡°íšŒ"""
    result = await session.execute(select(Host).where(Host.id == host_id))
    host = result.scalar_one_or_none()
    
    if not host:
        raise HTTPException(status_code=404, detail="Host not found")
    
    return host


@router.get("/hosts/{host_id}/findings")
async def get_host_findings(
    host_id: int,
    scan_id: Optional[int] = None,
    collector_mode: Optional[str] = Query(None, description="í•„í„°: os, kernel, local, binary"),
    session: AsyncSession = Depends(get_db)
):
    """í˜¸ìŠ¤íŠ¸ì˜ ì·¨ì•½ì  ëª©ë¡ ì¡°íšŒ (ê¸°ë³¸: ìµœì‹  ìŠ¤ìº” ê²°ê³¼ë§Œ)
    
    collector_mode í•„í„°:
    - os: OS íŒ¨í‚¤ì§€ CVE (ì»¤ë„ ì œì™¸)
    - kernel: ì»¤ë„ CVE
    - local: ë¡œì»¬ ìŠ¤ìº” CVE
    - binary: ë°”ì´ë„ˆë¦¬ ê¸°ë°˜ CVE
    - ë¯¸ì§€ì •: ì „ì²´
    """
    # í˜¸ìŠ¤íŠ¸ í™•ì¸
    result = await session.execute(select(Host).where(Host.id == host_id))
    host = result.scalar_one_or_none()
    
    if not host:
        raise HTTPException(status_code=404, detail="Host not found")
    
    # scan_idê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ìµœì‹  ìŠ¤ìº”ë§Œ ì¡°íšŒ
    if scan_id is None:
        latest_scan = await session.execute(
            select(ScanHistory)
            .where(ScanHistory.host_id == host_id)
            .order_by(ScanHistory.scan_started.desc())
            .limit(1)
        )
        latest = latest_scan.scalar_one_or_none()
        if latest:
            scan_id = latest.id
    
    # Finding ì¿¼ë¦¬ + Package, CVE ì¡°ì¸
    query = (
        select(Finding, Package, CVE)
        .join(Package, Finding.package_id == Package.id)
        .join(CVE, Finding.cve_id == CVE.id)
        .where(Finding.host_id == host_id)
    )
    
    if scan_id:
        query = query.where(Finding.scan_id == scan_id)
    
    # collector_mode í•„í„° ì ìš©
    if collector_mode:
        query = query.where(Finding.collector_mode == collector_mode)
    
    result = await session.execute(query.order_by(CVE.cvss_score.desc().nullslast(), CVE.cvss_v3_score.desc().nullslast()))
    rows = result.all()
    
    findings_list = []
    for finding, package, cve in rows:
        # CVSS ì ìˆ˜: í†µí•© cvss_score ìš°ì„ , ì—†ìœ¼ë©´ v3 â†’ v2 fallback (ê¸°ì¡´ ë°ì´í„° í˜¸í™˜)
        cvss_score = cve.cvss_score or cve.cvss_v3_score or cve.cvss_v2_score
        
        findings_list.append({
            "id": finding.id,
            "host_id": finding.host_id,
            "package_name": package.name,
            "package_version": package.version,
            "cve_id": cve.cve_id,
            "cvss_score": cvss_score,
            "cvss_version": cve.cvss_version,  # CVSS ë²„ì „ ì •ë³´ ì¶”ê°€
            "cvss_v4_score": cve.cvss_v4_score,  # v4
            "cvss_v3_score": cve.cvss_v3_score,  # v3
            "cvss_v2_score": cve.cvss_v2_score,  # v2
            "epss_score": cve.epss_score,
            "is_kev": cve.is_kev,
            "risk_level": finding.risk_level,
            "status": finding.status,
            "discovered_at": finding.discovered_at,
            "collector_mode": finding.collector_mode,
            "evidence": finding.evidence,
            "data_confidence": finding.data_confidence,
            "priority_score": finding.priority_score,
            "priority_level": finding.priority_level,
            "has_patch_available": finding.has_patch_available,
            "patch_version": finding.patch_version,
            # Package process information from Finding model
            "pkg_is_running": finding.pkg_is_running,
            "pkg_is_service": finding.pkg_is_service,
            "pkg_listening_ports": finding.pkg_listening_ports,
            "pkg_last_used": finding.pkg_last_used,
        })
    
    return findings_list


@router.get("/hosts/{host_id}/scan-history")
async def get_host_scan_history(
    host_id: int,
    limit: int = Query(20, le=100),
    session: AsyncSession = Depends(get_db)
):
    """í˜¸ìŠ¤íŠ¸ì˜ ìŠ¤ìº” íˆìŠ¤í† ë¦¬ ëª©ë¡ ì¡°íšŒ (ê³¼ê±° ìŠ¤ìº” ê²°ê³¼ ë¹„êµìš©)"""
    from sqlalchemy import func, case
    
    # í˜¸ìŠ¤íŠ¸ í™•ì¸
    result = await session.execute(select(Host).where(Host.id == host_id))
    host = result.scalar_one_or_none()
    
    if not host:
        raise HTTPException(status_code=404, detail="Host not found")
    
    # ScanHistory + Finding ê°œìˆ˜ ì¡°íšŒ
    query = (
        select(
            ScanHistory,
            func.count(Finding.id).label("findings_count"),
            func.sum(case((CVE.cvss_v3_score >= 7.0, 1), else_=0)).label("high_risk_count")
        )
        .outerjoin(Finding, Finding.scan_id == ScanHistory.id)
        .outerjoin(CVE, Finding.cve_id == CVE.id)
        .where(ScanHistory.host_id == host_id)
        .group_by(ScanHistory.id)
        .order_by(ScanHistory.scan_started.desc())
        .limit(limit)
    )
    
    result = await session.execute(query)
    rows = result.all()
    
    history_list = []
    for scan, findings_count, high_risk_count in rows:
        history_list.append({
            "id": scan.id,
            "scan_started": scan.scan_started,
            "scan_completed": scan.scan_completed,
            "status": scan.status,
            "packages_found": scan.packages_found,
            "cves_found": findings_count or 0,  # ì‹¤ì œ Finding ê°œìˆ˜
            "high_risk_count": high_risk_count or 0,
        })
    
    return {
        "host_id": host_id,
        "hostname": host.hostname,
        "total_scans": len(history_list),
        "scans": history_list
    }


@router.get("/hosts/{host_id}/compare")
async def compare_scan_results(
    host_id: int,
    scan1: int = Query(..., description="ì²« ë²ˆì§¸ ìŠ¤ìº” ID (ì´ì „ ìŠ¤ìº”)"),
    scan2: int = Query(..., description="ë‘ ë²ˆì§¸ ìŠ¤ìº” ID (í˜„ì¬/ìµœì‹  ìŠ¤ìº”)"),
    session: AsyncSession = Depends(get_db)
):
    """ë‘ ìŠ¤ìº” ê²°ê³¼ ë¹„êµ (ì‹ ê·œ/í•´ê²°/ìœ ì§€ ì·¨ì•½ì  ë¶„ë¥˜)
    
    Returns:
        - new: scan2ì—ë§Œ ì¡´ì¬í•˜ëŠ” ì·¨ì•½ì  (ì‹ ê·œ ë°œê²¬)
        - resolved: scan1ì—ë§Œ ì¡´ì¬í•˜ëŠ” ì·¨ì•½ì  (í•´ê²°ë¨)
        - unchanged: ì–‘ìª½ ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ì·¨ì•½ì  (ë¯¸í•´ê²°)
        - summary: ì „ì²´ í†µê³„
    """
    # í˜¸ìŠ¤íŠ¸ í™•ì¸
    result = await session.execute(select(Host).where(Host.id == host_id))
    host = result.scalar_one_or_none()
    
    if not host:
        raise HTTPException(status_code=404, detail="Host not found")
    
    # ìŠ¤ìº” ì •ë³´ ì¡°íšŒ
    scan1_result = await session.execute(
        select(ScanHistory).where(
            ScanHistory.id == scan1,
            ScanHistory.host_id == host_id
        )
    )
    scan1_info = scan1_result.scalar_one_or_none()
    if not scan1_info:
        raise HTTPException(status_code=404, detail=f"Scan {scan1} not found for host {host_id}")
    
    scan2_result = await session.execute(
        select(ScanHistory).where(
            ScanHistory.id == scan2,
            ScanHistory.host_id == host_id
        )
    )
    scan2_info = scan2_result.scalar_one_or_none()
    if not scan2_info:
        raise HTTPException(status_code=404, detail=f"Scan {scan2} not found for host {host_id}")
    
    # scan1 ì·¨ì•½ì  ì¡°íšŒ (cve_idë¥¼ í‚¤ë¡œ)
    query1 = (
        select(Finding, Package, CVE)
        .join(Package, Finding.package_id == Package.id)
        .join(CVE, Finding.cve_id == CVE.id)
        .where(Finding.scan_id == scan1)
    )
    result1 = await session.execute(query1)
    
    # scan2 ì·¨ì•½ì  ì¡°íšŒ
    query2 = (
        select(Finding, Package, CVE)
        .join(Package, Finding.package_id == Package.id)
        .join(CVE, Finding.cve_id == CVE.id)
        .where(Finding.scan_id == scan2)
    )
    result2 = await session.execute(query2)
    
    def to_dict(finding, package, cve):
        cvss_score = cve.cvss_v3_score or cve.cvss_v2_score or 0
        return {
            "id": finding.id,
            "package_name": package.name,
            "package_version": package.version,
            "cve_id": cve.cve_id,
            "cvss_score": cvss_score,
            "epss_score": cve.epss_score,
            "is_kev": cve.is_kev,
            "risk_level": finding.risk_level,
            "discovered_at": finding.discovered_at,
        }
    
    # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (CVE IDë¥¼ í‚¤ë¡œ)
    scan1_findings = {}
    for f, p, c in result1.all():
        key = (c.cve_id, p.name)  # CVE + íŒ¨í‚¤ì§€ëª…ìœ¼ë¡œ ì‹ë³„
        scan1_findings[key] = to_dict(f, p, c)
    
    scan2_findings = {}
    for f, p, c in result2.all():
        key = (c.cve_id, p.name)
        scan2_findings[key] = to_dict(f, p, c)
    
    keys1 = set(scan1_findings.keys())
    keys2 = set(scan2_findings.keys())
    
    # ì‹œê°„ìˆœìœ¼ë¡œ older/newer ê²°ì •
    scan1_time = scan1_info.scan_started or scan1_info.scan_completed
    scan2_time = scan2_info.scan_started or scan2_info.scan_completed
    
    if scan1_time and scan2_time and scan1_time > scan2_time:
        # scan1ì´ ë” ìµœì‹ ì´ë©´ swap
        scan1_info, scan2_info = scan2_info, scan1_info
        scan1_findings, scan2_findings = scan2_findings, scan1_findings
        keys1, keys2 = keys2, keys1
    
    # ë¶„ë¥˜ (older=scan1, newer=scan2 ê¸°ì¤€)
    new_keys = keys2 - keys1  # scan2ì—ë§Œ ìˆìŒ (ì‹ ê·œ)
    resolved_keys = keys1 - keys2  # scan1ì—ë§Œ ìˆìŒ (í•´ê²°ë¨)
    unchanged_keys = keys1 & keys2  # ì–‘ìª½ì— ë‹¤ ìˆìŒ (ë¯¸í•´ê²°)
    
    new_findings = [scan2_findings[k] for k in new_keys]
    resolved_findings = [scan1_findings[k] for k in resolved_keys]
    unchanged_findings = [scan2_findings[k] for k in unchanged_keys]
    
    # CVSS ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    new_findings.sort(key=lambda x: x["cvss_score"] or 0, reverse=True)
    resolved_findings.sort(key=lambda x: x["cvss_score"] or 0, reverse=True)
    unchanged_findings.sort(key=lambda x: x["cvss_score"] or 0, reverse=True)
    
    # í†µê³„ ê³„ì‚°
    def count_high_risk(findings):
        return sum(1 for f in findings if (f["cvss_score"] or 0) >= 7.0)
    
    return {
        "host_id": host_id,
        "hostname": host.hostname,
        "scan_old": {
            "id": scan1_info.id,
            "scan_started": scan1_info.scan_started,
            "cves_found": len(scan1_findings),
        },
        "scan_new": {
            "id": scan2_info.id,
            "scan_started": scan2_info.scan_started,
            "cves_found": len(scan2_findings),
        },
        "summary": {
            "new_count": len(new_findings),
            "resolved_count": len(resolved_findings),
            "unchanged_count": len(unchanged_findings),
            "new_high_risk": count_high_risk(new_findings),
            "resolved_high_risk": count_high_risk(resolved_findings),
            "unchanged_high_risk": count_high_risk(unchanged_findings),
        },
        "new": new_findings,  # ì‹ ê·œ ë°œê²¬ëœ ì·¨ì•½ì 
        "resolved": resolved_findings,  # í•´ê²°ëœ ì·¨ì•½ì 
        "unchanged": unchanged_findings,  # ì•„ì§ ë‚¨ì•„ìˆëŠ” ì·¨ì•½ì 
    }


@router.delete("/hosts/{host_id}")
async def delete_remote_host(
    host_id: int,
    session: AsyncSession = Depends(get_db)
):
    """ì›ê²© í˜¸ìŠ¤íŠ¸ ì‚­ì œ"""
    result = await session.execute(select(Host).where(Host.id == host_id))
    host = result.scalar_one_or_none()
    
    if not host:
        raise HTTPException(status_code=404, detail="Host not found")
    
    hostname = host.hostname
    
    # Audit log
    audit = AuditLog(
        actor="system",
        action="host_delete",
        target_type="host",
        target_id=host_id,
        target_name=hostname,
        result="success"
    )
    session.add(audit)
    
    await session.delete(host)
    await session.commit()
    
    return {"message": f"Host '{hostname}' deleted successfully", "host_id": host_id}


@router.put("/hosts/{host_id}")
async def update_remote_host(
    host_id: int,
    request: HostCreateRequest,
    session: AsyncSession = Depends(get_db)
):
    """ì›ê²© í˜¸ìŠ¤íŠ¸ ì •ë³´ ìˆ˜ì •"""
    result = await session.execute(select(Host).where(Host.id == host_id))
    host = result.scalar_one_or_none()
    
    if not host:
        raise HTTPException(status_code=404, detail="Host not found")
    
    # ì—…ë°ì´íŠ¸
    host.hostname = request.hostname
    host.ip_address = request.ip_address
    host.zone = request.zone
    host.os_type = request.os_type
    host.ssh_port = request.ssh_port
    host.ssh_username = request.ssh_username
    host.auth_method = request.auth_method
    host.ssh_key_path = request.ssh_key_path
    host.ssh_password = request.ssh_password
    host.tags = request.tags
    host.owner = request.owner
    host.description = request.description
    host.is_allowed = request.is_allowed
    
    # Audit log
    audit = AuditLog(
        actor="system",
        action="host_update",
        target_type="host",
        target_id=host_id,
        target_name=host.hostname,
        details=json.dumps(request.dict()),
        result="success"
    )
    session.add(audit)
    
    await session.commit()
    await session.refresh(host)
    
    return host


@router.patch("/hosts/{host_id}/allowlist")
async def toggle_host_allowlist(
    host_id: int,
    is_allowed: bool,
    session: AsyncSession = Depends(get_db)
):
    """í˜¸ìŠ¤íŠ¸ allowlist ìƒíƒœ ë³€ê²½"""
    result = await session.execute(select(Host).where(Host.id == host_id))
    host = result.scalar_one_or_none()
    
    if not host:
        raise HTTPException(status_code=404, detail="Host not found")
    
    host.is_allowed = is_allowed
    
    # Audit log
    audit = AuditLog(
        actor="system",
        action="allowlist_change",
        target_type="host",
        target_id=host_id,
        target_name=host.hostname,
        details=json.dumps({"is_allowed": is_allowed}),
        result="success"
    )
    session.add(audit)
    
    await session.commit()
    
    return {
        "host_id": host_id,
        "hostname": host.hostname,
        "is_allowed": is_allowed,
        "message": f"Host {'added to' if is_allowed else 'removed from'} allowlist"
    }


# === Scan Endpoints ===

@router.post("/scan")
async def start_remote_scan_from_body(
    request: ScanRequest,
    background_tasks: BackgroundTasks = None,
    session: AsyncSession = Depends(get_db)
):
    """
    ì›ê²© í˜¸ìŠ¤íŠ¸ ìŠ¤ìº” ì‹œì‘ (bodyì—ì„œ host_id ë°›ê¸°)
    """
    if not request.host_id:
        raise HTTPException(status_code=400, detail="host_id is required")
    
    return await _start_scan_internal(request.host_id, request, background_tasks, session)


@router.post("/scan/{host_id}")
async def start_remote_scan(
    host_id: int,
    request: ScanRequest = None,
    background_tasks: BackgroundTasks = None,
    session: AsyncSession = Depends(get_db)
):
    """
    ì›ê²© í˜¸ìŠ¤íŠ¸ ìŠ¤ìº” ì‹œì‘ (pathì—ì„œ host_id ë°›ê¸°)
    
    í”„ë¦¬ì…‹:
    - fast: ë¹ ë¥¸ Discovery + ìµœì†Œ ìˆ˜ì§‘ (10-30ì´ˆ)
    - standard: Discovery + íŒ¨í‚¤ì§€ ì „ì²´ + CVE ë¶„ì„ (1-5ë¶„)
    - deep: ì‹¬ì¸µ ë¶„ì„ + ë°”ì´ë„ˆë¦¬ ë²„ì „ (5-15ë¶„)
    
    ì£¼ì˜: ìŠ¤ìº” ëŒ€ìƒì€ ë°˜ë“œì‹œ allowlistì— ë“±ë¡ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    """
    if request is None:
        request = ScanRequest()
    
    return await _start_scan_internal(host_id, request, background_tasks, session)


async def _start_scan_internal(
    host_id: int,
    request: ScanRequest,
    background_tasks: BackgroundTasks,
    session: AsyncSession
):
    """ìŠ¤ìº” ì‹œì‘ ë‚´ë¶€ êµ¬í˜„"""
    # í˜¸ìŠ¤íŠ¸ ì¡°íšŒ ë° allowlist ê²€ì¦
    result = await session.execute(select(Host).where(Host.id == host_id))
    host = result.scalar_one_or_none()
    
    if not host:
        raise HTTPException(status_code=404, detail="Host not found")
    
    if not getattr(host, 'is_allowed', True):
        raise HTTPException(
            status_code=403,
            detail=f"Host '{host.hostname}' is not in allowlist. "
                   "ìŠ¤ìº” ëŒ€ìƒì€ ë°˜ë“œì‹œ allowlistì— ë“±ë¡ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
        )
    
    # ìŠ¤ìº” ì„¤ì • ìƒì„±
    try:
        preset = ScanPreset(request.preset)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid preset: {request.preset}")
    
    config = ScanConfig.from_preset(preset)
    config.categories = request.categories
    config.filter_patched = request.filter_patched
    config.filter_old_cve = request.filter_old_cve
    config.cve_years = request.cve_years
    
    # ScanJob ë ˆì½”ë“œ ìƒì„±
    scan_job = ScanJob(
        host_id=host_id,
        status="pending",
        preset=request.preset,
        initiated_by=request.initiated_by,
    )
    session.add(scan_job)
    await session.flush()
    job_id = scan_job.id
    
    # Audit log
    audit = AuditLog(
        actor=request.initiated_by,
        action="scan_start",
        target_type="host",
        target_id=host_id,
        target_name=host.hostname,
        preset=request.preset,
        details=json.dumps({
            "preset": request.preset,
            "categories": request.categories,
            "filter_patched": request.filter_patched,
        }),
        result="pending"
    )
    session.add(audit)
    await session.commit()
    
    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìŠ¤ìº” ì‹¤í–‰
    background_tasks.add_task(
        _run_scan_background,
        job_id,
        host_id,
        config
    )
    
    return {
        "job_id": job_id,
        "host_id": host_id,
        "hostname": host.hostname,
        "preset": request.preset,
        "status": "pending",
        "message": f"Scan job {job_id} created. Use GET /api/remote/jobs/{job_id} to check status."
    }


async def _run_scan_background(job_id: int, host_id: int, config: ScanConfig):
    """ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ìº” ì‹¤í–‰"""
    from ..models.database import async_session_maker
    
    async with async_session_maker() as session:
        try:
            # ScanJob ìƒíƒœ ì—…ë°ì´íŠ¸
            result = await session.execute(
                select(ScanJob).where(ScanJob.id == job_id)
            )
            scan_job = result.scalar_one_or_none()
            
            if scan_job:
                scan_job.status = "running"
                scan_job.started_at = datetime.now(KST)
                await session.commit()
            
            # ìŠ¤ìº” ì‹¤í–‰
            scanner = RemoteScanner(host_id, config, session, job_id=job_id)
            
            # ì§„í–‰ ìƒí™© ì½œë°± ì„¤ì • (ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸)
            async def update_progress(phase: str, progress: int, message: str):
                # ë°±ê·¸ë¼ìš´ë“œë¡œ ë¹„ë™ê¸° ì‹¤í–‰ (ìŠ¤ìº” ì†ë„ì— ì˜í–¥ ì—†ë„ë¡)
                async def _update():
                    max_retries = 3
                    for attempt in range(max_retries):
                        try:
                            # ë³„ë„ ì„¸ì…˜ ì‚¬ìš© (ë™ì‹œì„± ë¬¸ì œ ë°©ì§€)
                            async with async_session_maker() as update_session:
                                # SQLite timeout ì„¤ì •
                                from sqlalchemy import text
                                await update_session.execute(text("PRAGMA busy_timeout = 5000"))

                                result = await update_session.execute(
                                    select(ScanJob).where(ScanJob.id == job_id)
                                )
                                job = result.scalar_one_or_none()
                                if job:
                                    # ì´ë¯¸ ì™„ë£Œëœ ìƒíƒœë©´ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŒ
                                    if job.progress_percent == 100:
                                        break
                                    # progressê°€ í˜„ì¬ DB ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ ë¬´ì‹œ (ë ˆì´ìŠ¤ ì»¨ë””ì…˜ ë°©ì§€)
                                    if progress < job.progress_percent and phase != "complete":
                                        break
                                    job.current_phase = phase
                                    job.progress_percent = progress
                                    job.progress_message = message
                                    await update_session.commit()
                                break  # ì„±ê³µ
                        except Exception as e:
                            if attempt < max_retries - 1:
                                await asyncio.sleep(0.1 * (attempt + 1))  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                            # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œë„ ì‹¤íŒ¨í•˜ë©´ ì¡°ìš©íˆ ë¬´ì‹œ (ìŠ¤ìº”ì€ ê³„ì†)

                # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰ (await í•˜ì§€ ì•ŠìŒ)
                import asyncio
                asyncio.create_task(_update())
            
            scanner.set_progress_callback(update_progress)
            scan_result = await scanner.run()
            
            # ë°±ê·¸ë¼ìš´ë“œ progress ì—…ë°ì´íŠ¸ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
            await asyncio.sleep(0.5)
            
            # ê²°ê³¼ ì €ì¥ - ë°˜ë“œì‹œ progress_percent = 100ìœ¼ë¡œ ì„¤ì •
            if scan_job:
                result = await session.execute(
                    select(ScanJob).where(ScanJob.id == job_id)
                )
                scan_job = result.scalar_one_or_none()
                
                scan_job.status = "completed" if scan_result["success"] else "failed"
                scan_job.completed_at = datetime.now(KST)
                scan_job.current_phase = "complete"
                scan_job.progress_percent = 100  # ë°˜ë“œì‹œ 100%
                scan_job.progress_message = "Scan completed"  # ë©”ì‹œì§€ë„ ì—…ë°ì´íŠ¸
                scan_job.packages_found = scan_result.get("packages_scanned", 0)
                scan_job.cves_found = scan_result.get("cves_found", 0)
                scan_job.high_risk_count = scan_result.get("high_risk_count", 0)
                scan_job.scan_history_id = scan_result.get("scan_history_id")
                scan_job.snapshot_id = scan_result.get("snapshot_id")
                
                if scan_result.get("discovery"):
                    scan_job.discovery_result = json.dumps(scan_result["discovery"])
                
                if scan_result.get("errors"):
                    scan_job.error_message = "; ".join(scan_result["errors"])
                
                await session.commit()
                
                # ìµœì¢… í™•ì¸ì„ ìœ„í•´ í•œë²ˆ ë” 100% ì„¤ì • (ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸° í›„)
                await asyncio.sleep(0.3)
                result = await session.execute(
                    select(ScanJob).where(ScanJob.id == job_id)
                )
                scan_job = result.scalar_one_or_none()
                if scan_job and scan_job.progress_percent != 100:
                    scan_job.progress_percent = 100
                    scan_job.current_phase = "complete"
                    scan_job.progress_message = "Scan completed"
                    await session.commit()
                
        except Exception as e:
            # ì—ëŸ¬ ì²˜ë¦¬
            result = await session.execute(
                select(ScanJob).where(ScanJob.id == job_id)
            )
            scan_job = result.scalar_one_or_none()
            
            if scan_job:
                scan_job.status = "failed"
                scan_job.completed_at = datetime.now(KST)
                scan_job.error_message = str(e)
                await session.commit()


@router.get("/jobs/{job_id}")
async def get_scan_job(
    job_id: int,
    session: AsyncSession = Depends(get_db)
):
    """ìŠ¤ìº” ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    result = await session.execute(
        select(ScanJob).where(ScanJob.id == job_id)
    )
    job = result.scalar_one_or_none()
    
    if not job:
        raise HTTPException(status_code=404, detail="Scan job not found")
    
    # finished_at ì¶”ê°€ (JS í˜¸í™˜ì„±)
    return {
        "id": job.id,
        "host_id": job.host_id,
        "status": job.status,
        "preset": job.preset,
        "current_phase": job.current_phase,
        "progress_percent": job.progress_percent,
        "progress_message": job.progress_message,
        "created_at": job.created_at,
        "started_at": job.started_at,
        "completed_at": job.completed_at,
        "finished_at": job.completed_at,  # alias
        "packages_found": job.packages_found,
        "cves_found": job.cves_found,
        "findings_count": job.cves_found,  # alias for history
        "high_risk_count": job.high_risk_count,
        "error_message": job.error_message,
        "scan_id": job.scan_history_id,  # ScanJobì— ì €ì¥ëœ scan_history_id ì‚¬ìš©
    }


@router.get("/jobs")
async def list_scan_jobs(
    host_id: Optional[int] = None,
    status: Optional[str] = None,
    limit: int = Query(50, le=200),
    session: AsyncSession = Depends(get_db)
):
    """ìŠ¤ìº” ì‘ì—… ëª©ë¡ ì¡°íšŒ"""
    query = select(ScanJob).order_by(ScanJob.created_at.desc()).limit(limit)
    
    if host_id:
        query = query.where(ScanJob.host_id == host_id)
    if status:
        query = query.where(ScanJob.status == status)
    
    result = await session.execute(query)
    jobs = result.scalars().all()
    
    # finished_at ì¶”ê°€ (JS í˜¸í™˜ì„±)
    return [
        {
            "id": job.id,
            "host_id": job.host_id,
            "status": job.status,
            "preset": job.preset,
            "current_phase": job.current_phase,
            "progress_percent": job.progress_percent,
            "progress_message": job.progress_message,
            "created_at": job.created_at,
            "started_at": job.started_at,
            "completed_at": job.completed_at,
            "finished_at": job.completed_at,  # alias
            "packages_found": job.packages_found,
            "cves_found": job.cves_found,
            "findings_count": job.cves_found,  # alias for history
            "high_risk_count": job.high_risk_count,
            "error_message": job.error_message,
        }
        for job in jobs
    ]


@router.post("/jobs/{job_id}/cancel")
async def cancel_scan_job(
    job_id: int,
    session: AsyncSession = Depends(get_db)
):
    """ìŠ¤ìº” ì‘ì—… ì·¨ì†Œ"""
    result = await session.execute(
        select(ScanJob).where(ScanJob.id == job_id)
    )
    job = result.scalar_one_or_none()
    
    if not job:
        raise HTTPException(status_code=404, detail="Scan job not found")
    
    if job.status in ("completed", "failed", "cancelled"):
        raise HTTPException(
            status_code=400,
            detail=f"Cannot cancel job with status '{job.status}'"
        )
    
    job.status = "cancelled"
    job.completed_at = datetime.now(KST)
    job.error_message = "Cancelled by user"
    
    # ì—°ê´€ëœ ScanHistoryë„ ì·¨ì†Œ ì²˜ë¦¬
    try:
        from ..models.schemas import ScanHistory
        scan_results = await session.execute(
            select(ScanHistory).where(
                ScanHistory.host_id == job.host_id,
                ScanHistory.status == "running"
            )
        )
        running_scans = scan_results.scalars().all()
        for scan in running_scans:
            scan.status = "cancelled"
            scan.scan_completed = datetime.now(KST)
    except Exception:
        pass  # ScanHistory ì—…ë°ì´íŠ¸ ì‹¤íŒ¨í•´ë„ ì·¨ì†ŒëŠ” ì§„í–‰
    
    await session.commit()
    
    # JobRunnerì˜ ì¸ë©”ëª¨ë¦¬ ìƒíƒœë„ ì—…ë°ì´íŠ¸
    try:
        from ..services.job_runner import get_job_runner
        runner = get_job_runner()
        await runner.cancel_job(job_id)
    except Exception:
        pass  # JobRunner ì—…ë°ì´íŠ¸ ì‹¤íŒ¨í•´ë„ DBëŠ” ì´ë¯¸ ì·¨ì†Œë¨
    
    return {"job_id": job_id, "status": "cancelled"}


@router.delete("/jobs/{job_id}")
async def delete_scan_job(
    job_id: int,
    session: AsyncSession = Depends(get_db)
):
    """ìŠ¤ìº” ì‘ì—… ì‚­ì œ"""
    result = await session.execute(
        select(ScanJob).where(ScanJob.id == job_id)
    )
    job = result.scalar_one_or_none()
    
    if not job:
        raise HTTPException(status_code=404, detail="Scan job not found")
    
    await session.delete(job)
    await session.commit()
    
    return {"message": f"Job {job_id} deleted", "job_id": job_id}


# === Asset Snapshot Endpoints ===

@router.get("/snapshots/{host_id}", response_model=List[SnapshotResponse])
async def get_host_snapshots(
    host_id: int,
    limit: int = Query(10, le=50),
    session: AsyncSession = Depends(get_db)
):
    """í˜¸ìŠ¤íŠ¸ì˜ ìì‚° ìŠ¤ëƒ…ìƒ· ëª©ë¡ ì¡°íšŒ"""
    result = await session.execute(
        select(AssetSnapshot)
        .where(AssetSnapshot.host_id == host_id)
        .order_by(AssetSnapshot.created_at.desc())
        .limit(limit)
    )
    return result.scalars().all()


@router.get("/snapshots/{host_id}/latest")
async def get_latest_snapshot(
    host_id: int,
    session: AsyncSession = Depends(get_db)
):
    """í˜¸ìŠ¤íŠ¸ì˜ ìµœì‹  ìŠ¤ëƒ…ìƒ· ìƒì„¸ ì¡°íšŒ"""
    result = await session.execute(
        select(AssetSnapshot)
        .where(AssetSnapshot.host_id == host_id)
        .order_by(AssetSnapshot.created_at.desc())
        .limit(1)
    )
    snapshot = result.scalar_one_or_none()
    
    if not snapshot:
        raise HTTPException(status_code=404, detail="No snapshots found for this host")
    
    # ìƒì„¸ ì •ë³´ í¬í•¨
    return {
        "id": snapshot.id,
        "host_id": snapshot.host_id,
        "created_at": snapshot.created_at,
        "os_family": snapshot.os_family,
        "distro_id": snapshot.distro_id,
        "distro_version": snapshot.distro_version,
        "pkg_manager": snapshot.pkg_manager,
        "arch": snapshot.arch,
        "kernel_version": snapshot.kernel_version,
        "is_busybox": snapshot.is_busybox,
        "has_systemd": snapshot.has_systemd,
        "capabilities": json.loads(snapshot.capabilities) if snapshot.capabilities else [],
        "confidence_discovery": snapshot.confidence_discovery,
        "packages_hash": snapshot.packages_hash,
        "binaries_hash": snapshot.binaries_hash,
        "collector_mode": snapshot.collector_mode,
        "collection_duration_sec": snapshot.collection_duration_sec,
        "packages_count": len(json.loads(snapshot.packages_json)) if snapshot.packages_json else 0,
        "binaries_count": len(json.loads(snapshot.binaries_json)) if snapshot.binaries_json else 0,
    }


# === Audit Log Endpoints ===

@router.get("/audit")
async def get_audit_logs(
    host_id: Optional[int] = None,
    action: Optional[str] = None,
    limit: int = Query(100, le=500),
    session: AsyncSession = Depends(get_db)
):
    """ê°ì‚¬ ë¡œê·¸ ì¡°íšŒ"""
    query = select(AuditLog).order_by(AuditLog.timestamp.desc()).limit(limit)
    
    if host_id:
        query = query.where(AuditLog.target_id == host_id)
    if action:
        query = query.where(AuditLog.action == action)
    
    result = await session.execute(query)
    logs = result.scalars().all()
    
    return [
        {
            "id": log.id,
            "timestamp": log.timestamp,
            "actor": log.actor,
            "action": log.action,
            "target_type": log.target_type,
            "target_id": log.target_id,
            "target_name": log.target_name,
            "preset": log.preset,
            "result": log.result,
        }
        for log in logs
    ]


# === Presets Info Endpoint ===

@router.get("/presets")
async def get_scan_presets():
    """ìŠ¤ìº” í”„ë¦¬ì…‹ ì •ë³´ ì¡°íšŒ"""
    return {
        "presets": [
            {
                "name": "fast",
                "description": "ğŸš€ ë¹ ë¥¸ ìŠ¤ìº”: Discovery + ë³´ì•ˆ/ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ë§Œ",
                "estimated_time": "10-30ì´ˆ",
                "details": "íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €(apk/dpkg/rpm)ë¡œ ë³´ì•ˆ ê´€ë ¨ íŒ¨í‚¤ì§€ë§Œ ìˆ˜ì§‘. ì»¤ë„ ì •ë³´ ì—†ìŒ.",
                "collect_packages": True,
                "collect_binaries": False,
                "collect_kernel_info": False,
                "categories": ["security", "system"],
            },
            {
                "name": "standard",
                "description": "âš¡ í‘œì¤€ ìŠ¤ìº”: ëª¨ë“  íŒ¨í‚¤ì§€ + ì»¤ë„ ì •ë³´ + CVE ë§¤ì¹­",
                "estimated_time": "1-5ë¶„",
                "details": "íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €ë¡œ ì „ì²´ íŒ¨í‚¤ì§€ ìˆ˜ì§‘, ì»¤ë„ ë²„ì „ í™•ì¸, CVE DB ë§¤ì¹­. ë°”ì´ë„ˆë¦¬ ë¶„ì„ ì—†ìŒ.",
                "collect_packages": True,
                "collect_binaries": False,
                "collect_kernel_info": True,
                "categories": ["all"],
            },
            {
                "name": "deep",
                "description": "ğŸ” ì‹¬ì¸µ ìŠ¤ìº”: ë°”ì´ë„ˆë¦¬ ë²„ì „ ë¶„ì„ + í¬íŠ¸ ìŠ¤ìº”",
                "estimated_time": "5-15ë¶„",
                "details": "íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € ì—†ëŠ” ë°”ì´ë„ˆë¦¬ë„ ë²„ì „ ì¶”ì¶œ(openssl, nginx ë“±), ë„¤íŠ¸ì›Œí¬ í¬íŠ¸ ìŠ¤ìº” ì˜µì…˜.",
                "collect_packages": True,
                "collect_binaries": True,
                "collect_kernel_info": True,
                "categories": ["all"],
                "port_scan_option": True,
            },
        ]
    }


# === PDF Report Endpoint for Remote Scans ===

@router.get("/report/{host_id}/pdf")
async def get_remote_scan_pdf_report(
    host_id: int,
    job_id: Optional[int] = None,
    session: AsyncSession = Depends(get_db)
):
    """ì›ê²© ìŠ¤ìº” ê²°ê³¼ PDF ë³´ê³ ì„œ ìƒì„±
    
    Args:
        host_id: í˜¸ìŠ¤íŠ¸ ID
        job_id: íŠ¹ì • ìŠ¤ìº” ì‘ì—… ID (ì—†ìœ¼ë©´ ìµœì‹  ìŠ¤ìº” ê²°ê³¼)
    """
    from vulnscan.core.pdf_generator import VulnerabilityPDFGenerator
    from datetime import datetime
    from fastapi.responses import Response
    
    # Get host
    result = await session.execute(select(Host).where(Host.id == host_id))
    host = result.scalar_one_or_none()
    if not host:
        raise HTTPException(status_code=404, detail="Host not found")
    
    # Get latest snapshot
    snapshot_query = select(AssetSnapshot).where(
        AssetSnapshot.host_id == host_id
    ).order_by(AssetSnapshot.collected_at.desc())
    
    if job_id:
        snapshot_query = snapshot_query.where(AssetSnapshot.job_id == job_id)
    
    snapshot_result = await session.execute(snapshot_query.limit(1))
    snapshot = snapshot_result.scalar_one_or_none()
    
    # Get findings for this host
    findings_query = select(Finding).where(Finding.host_id == host_id)
    findings_result = await session.execute(findings_query)
    findings_list = findings_result.scalars().all()
    
    # Prepare data
    host_info = {
        "hostname": host.hostname,
        "ip_address": host.ip_address,
        "os_type": host.distro_id or host.os_type or "Unknown",
        "os_version": host.os_version or "",
    }
    
    # Calculate stats
    findings_data = []
    high_risk_count = 0
    unauthorized_count = 0
    
    for f in findings_list:
        finding_dict = {
            "package_name": f.package_name if hasattr(f, 'package_name') else "Unknown",
            "package_version": f.package_version if hasattr(f, 'package_version') else "",
            "cve_id": f.cve_id,
            "cvss_score": f.cvss_score,
            "risk_level": f.risk_level,
            "data_confidence": f.data_confidence,
            "collector_mode": f.collector_mode,
            "evidence": f.evidence,
        }
        findings_data.append(finding_dict)
        
        if f.cvss_score and f.cvss_score >= 7.0:
            high_risk_count += 1
        if f.is_unauthorized_access:
            unauthorized_count += 1
    
    dashboard_stats = {
        "total_findings": len(findings_data),
        "high_risk_count": high_risk_count,
        "unauthorized_count": unauthorized_count,
    }
    
    package_summary = {
        "total_packages": len(set(f.get("package_name") for f in findings_data))
    }
    
    # Scan config for report
    scan_config = {
        "scan_type": "remote",
        "preset": "standard",  # TODO: Get from job if available
        "overall_confidence": snapshot.discovery_confidence if snapshot else "unknown",
        "discovery_info": {
            "distro_id": host.distro_id,
            "pkg_manager": host.pkg_manager,
            "arch": host.arch,
            "kernel_version": host.kernel_version,
            "is_busybox": host.is_busybox,
            "has_systemd": host.has_systemd,
            "confidence": snapshot.discovery_confidence if snapshot else "unknown",
        } if host.distro_id else None,
    }
    
    # Generate PDF
    pdf_generator = VulnerabilityPDFGenerator()
    pdf_bytes = pdf_generator.generate_report(
        host_info=host_info,
        dashboard_stats=dashboard_stats,
        findings=findings_data,
        package_summary=package_summary,
        scan_config=scan_config
    )
    
    # Return PDF
    filename = f"remote_scan_report_{host.hostname}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
    
    return Response(
        content=pdf_bytes,
        media_type="application/pdf",
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )


# === SBOM Generation Endpoint ===

@router.get("/sbom/{host_id}")
async def get_host_sbom(
    host_id: int,
    format: str = Query("json", regex="^(json|xml)$"),
    session: AsyncSession = Depends(get_db)
):
    """
    í˜¸ìŠ¤íŠ¸ì˜ SBOM(Software Bill of Materials) ìƒì„±
    
    Alpine ê°™ì€ ê²½ëŸ‰ ë¦¬ëˆ…ìŠ¤ì—ì„œ ìœ ìš©:
    - OS/ì»¤ë„ ì •ë³´ í¬í•¨
    - CPE ìë™ ìƒì„±ìœ¼ë¡œ CVE ë§¤ì¹­
    - CycloneDX 1.4 í‘œì¤€
    """
    from ..core.sbom_generator import generate_sbom_for_host
    
    try:
        sbom = await generate_sbom_for_host(session, host_id)

        if format == "json":
            return sbom
        else:
            # XML ë³€í™˜ì€ ì¶”í›„ êµ¬í˜„
            raise HTTPException(status_code=400, detail="XML format not yet supported")

    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"SBOM generation failed: {str(e)}")


# === NVD ë°ì´í„° ë‹¤ìš´ë¡œë“œ ===

class NVDDownloadRequest(BaseModel):
    """NVD ë…„ë„ ë²”ìœ„ ë‹¤ìš´ë¡œë“œ ìš”ì²­"""
    start_year: int = Field(2026, ge=1999, le=2026, description="ì‹œì‘ ë…„ë„ (ê¸°ë³¸ê°’: 2026)")
    end_year: int = Field(2026, ge=1999, le=2026, description="ì¢…ë£Œ ë…„ë„ (ê¸°ë³¸ê°’: 2026)")


@router.post("/nvd/download-range")
async def download_nvd_range(
    request: NVDDownloadRequest,
    background_tasks: BackgroundTasks
):
    """
    ë…„ë„ ë²”ìœ„ì˜ NVD CVE ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ìºì‹œì— ì €ì¥

    ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìœ¼ë¡œ ì‹¤í–‰ë˜ë©°, ì™„ë£Œê¹Œì§€ ìˆ˜ì‹­ ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŒ
    """
    from ..core.nvd_client import NVDClient
    import asyncio

    start_year = request.start_year
    end_year = request.end_year

    if start_year > end_year:
        raise HTTPException(status_code=400, detail="ì‹œì‘ ë…„ë„ëŠ” ì¢…ë£Œ ë…„ë„ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤")

    # ì „ì—­ ì§„í–‰ ìƒí™© ì €ì¥ì†Œ (ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì €ì¥)
    download_progress = {
        "status": "running",
        "current_year": start_year,
        "start_year": start_year,
        "end_year": end_year,
        "completed_years": 0,
        "total_years": end_year - start_year + 1,
        "total_cves": 0,
        "message": f"{start_year}ë…„ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì¤‘..."
    }
    
    # ì „ì—­ ë³€ìˆ˜ì— ì €ì¥ (APIì—ì„œ ì¡°íšŒ ê°€ëŠ¥)
    router.download_progress = download_progress

    async def download_task():
        """ë°±ê·¸ë¼ìš´ë“œ ë‹¤ìš´ë¡œë“œ ì‘ì—…"""
        try:
            nvd_client = NVDClient()
            total_cves = 0

            for year in range(start_year, end_year + 1):
                download_progress["current_year"] = year
                download_progress["message"] = f"{year}ë…„ ë‹¤ìš´ë¡œë“œ ì¤‘..."
                
                result = await nvd_client.download_year_data(year)
                
                total_cves += result.get("total", 0)
                download_progress["completed_years"] = year - start_year + 1
                download_progress["total_cves"] = total_cves
                download_progress["message"] = f"{year}ë…„ ì™„ë£Œ ({result.get('total', 0)}ê°œ CVE)"

            # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ CPE ì¸ë±ìŠ¤ ë¹Œë“œ
            download_progress["message"] = "CPE ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘... (ìŠ¤ìº” ì†ë„ ìµœì í™”)"
            index_stats = await nvd_client.build_cpe_index()
            
            download_progress["status"] = "completed"
            download_progress["message"] = f"ì „ì²´ ì™„ë£Œ! {total_cves}ê°œ CVE ë‹¤ìš´ë¡œë“œ, {index_stats['packages']}ê°œ íŒ¨í‚¤ì§€ ì¸ë±ì‹±ë¨"
            download_progress["index_stats"] = index_stats

            print(f"[NVD ë²”ìœ„ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ] {start_year}-{end_year}: {total_cves}ê°œ CVE, ì¸ë±ìŠ¤: {index_stats['packages']}ê°œ íŒ¨í‚¤ì§€")

        except Exception as e:
            download_progress["status"] = "failed"
            download_progress["message"] = f"ì˜¤ë¥˜: {str(e)}"
            print(f"[NVD ë²”ìœ„ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨] {start_year}-{end_year}: {e}")

    # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰
    background_tasks.add_task(download_task)

    return {
        "status": "started",
        "start_year": start_year,
        "end_year": end_year,
        "message": f"{start_year}~{end_year}ë…„ NVD ë°ì´í„° ë‹¤ìš´ë¡œë“œê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
    }


@router.get("/nvd/download-progress")
async def get_download_progress():
    """NVD ë‹¤ìš´ë¡œë“œ ì§„í–‰ ìƒí™© ì¡°íšŒ"""
    if hasattr(router, 'download_progress'):
        return router.download_progress
    else:
        return {
            "status": "idle",
            "message": "ë‹¤ìš´ë¡œë“œ ì‘ì—… ì—†ìŒ"
        }


@router.get("/nvd/cache-stats")
async def get_nvd_cache_stats():
    """NVD ìºì‹œ í†µê³„ ì¡°íšŒ"""
    from ..core.nvd_client import NVDClient
    import sqlite3

    nvd_client = NVDClient()

    try:
        conn = sqlite3.connect(nvd_client._cache_db_path)
        cursor = conn.execute("SELECT COUNT(*) FROM nvd_cache")
        total_cached = cursor.fetchone()[0]

        # ë…„ë„ë³„ ìºì‹œ ì¡°íšŒ
        cursor = conn.execute(
            "SELECT keyword FROM nvd_cache WHERE keyword LIKE '__year_%__'"
        )
        year_caches = cursor.fetchall()
        years_cached = [row[0].replace("__year_", "").replace("__", "") for row in year_caches]

        conn.close()
        
        # ì¸ë±ìŠ¤ ìƒíƒœ ì¡°íšŒ
        index_stats = nvd_client.get_index_stats()

        return {
            "total_cached_items": total_cached,
            "years_cached": sorted(years_cached),
            "cache_db_path": nvd_client._cache_db_path,
            "index_loaded": index_stats["loaded"],
            "index_packages": index_stats["packages"],
            "index_years": index_stats["years"]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get cache stats: {str(e)}")


@router.get("/nvd/download-records")
async def get_nvd_download_records():
    """NVD ë‹¤ìš´ë¡œë“œ ê¸°ë¡ ì¡°íšŒ"""
    from ..core.nvd_client import NVDClient

    try:
        nvd_client = NVDClient()
        records = nvd_client.get_download_records()

        return {
            "records": records,
            "total_years": len(records)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get download records: {str(e)}")


@router.post("/nvd/build-index")
async def build_nvd_cpe_index():
    """
    CPE ì¸ë±ìŠ¤ ìˆ˜ë™ ë¹Œë“œ (ìŠ¤ìº” ì†ë„ ìµœì í™”)
    
    ë‹¤ìš´ë¡œë“œëœ CVE ë°ì´í„°ì—ì„œ íŒ¨í‚¤ì§€ëª… ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•˜ì—¬
    ìŠ¤ìº” ì‹œ ê²€ìƒ‰ ì†ë„ë¥¼ 10ë°° ì´ìƒ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
    
    - ìŠ¤ìº” ì „ì— ìë™ìœ¼ë¡œ ë¹Œë“œë˜ì§€ë§Œ, ìˆ˜ë™ìœ¼ë¡œë„ ë¹Œë“œ ê°€ëŠ¥
    - ì¸ë±ìŠ¤ëŠ” ë©”ëª¨ë¦¬ì— ì €ì¥ë˜ì–´ ì„œë²„ ì¬ì‹œì‘ ì‹œ ë‹¤ì‹œ ë¹Œë“œ í•„ìš”
    """
    from ..core.nvd_client import NVDClient

    try:
        nvd_client = NVDClient()
        
        # ë‹¤ìš´ë¡œë“œ ê¸°ë¡ í™•ì¸
        records = nvd_client.get_download_records()
        if not records:
            return {
                "status": "no_data",
                "message": "ë‹¤ìš´ë¡œë“œëœ CVE ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € NVD ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”."
            }
        
        # ì¸ë±ìŠ¤ ë¹Œë“œ
        stats = await nvd_client.build_cpe_index()
        
        return {
            "status": "completed",
            "message": f"CPE ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {stats['packages']}ê°œ íŒ¨í‚¤ì§€, {stats['cves']}ê°œ CVE",
            "stats": stats
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Index build failed: {str(e)}")


@router.get("/nvd/index-stats")
async def get_nvd_index_stats():
    """CPE ì¸ë±ìŠ¤ ìƒíƒœ ì¡°íšŒ"""
    from ..core.nvd_client import NVDClient

    try:
        nvd_client = NVDClient()
        stats = nvd_client.get_index_stats()
        
        return {
            "loaded": stats["loaded"],
            "packages": stats["packages"],
            "years": stats["years"],
            "message": "ì¸ë±ìŠ¤ ë¡œë“œë¨" if stats["loaded"] else "ì¸ë±ìŠ¤ ë¯¸ë¡œë“œ (ìŠ¤ìº” ì‹œ ìë™ ë¹Œë“œ)"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get index stats: {str(e)}")


@router.delete("/nvd/year/{year}")
async def delete_nvd_year_data(year: int):
    """íŠ¹ì • ë…„ë„ì˜ NVD ë°ì´í„° ì‚­ì œ"""
    from ..core.nvd_client import NVDClient

    if year < 1999 or year > 2026:
        raise HTTPException(status_code=400, detail="Invalid year (must be 1999-2026)")

    try:
        nvd_client = NVDClient()
        success = nvd_client.delete_year_data(year)

        if success:
            return {
                "status": "deleted",
                "year": year,
                "message": f"{year}ë…„ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
            }
        else:
            raise HTTPException(status_code=500, detail=f"Failed to delete {year} data")

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Delete failed: {str(e)}")


@router.get("/nvd/test-api/{year}")
async def test_nvd_api(year: int):
    """NVD API ì§ì ‘ í…ŒìŠ¤íŠ¸ (ë””ë²„ê¹…ìš©)"""
    import httpx

    start_date = f"{year}-01-01T00:00:00.000"
    end_date = f"{year}-01-31T23:59:59.999"
    url = f"https://services.nvd.nist.gov/rest/json/cves/2.0?pubStartDate={start_date}&pubEndDate={end_date}&resultsPerPage=10"

    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(url)

            if response.status_code == 200:
                data = response.json()
                return {
                    "status": "success",
                    "year": year,
                    "total_results": data.get("totalResults", 0),
                    "url": url,
                    "sample_cves": [v["cve"]["id"] for v in data.get("vulnerabilities", [])[:5]]
                }
            else:
                return {
                    "status": "error",
                    "year": year,
                    "status_code": response.status_code,
                    "url": url,
                    "error": response.text[:500]
                }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Test failed: {str(e)}")


# ==================== CVE Detail API ====================

@router.get("/cves/{cve_id}")
async def get_cve_detail(
    cve_id: str,
    session: AsyncSession = Depends(get_db)
):
    """
    CVE ìƒì„¸ ì •ë³´ ì¡°íšŒ (EPSS, KEV í¬í•¨)
    EPSS/KEV ì •ë³´ëŠ” í•­ìƒ ìµœì‹  ë°ì´í„°ë¡œ ì¡°íšŒ
    """
    result = await session.execute(
        select(CVE).where(CVE.cve_id == cve_id)
    )
    cve = result.scalar_one_or_none()
    
    if not cve:
        raise HTTPException(status_code=404, detail=f"CVE {cve_id} not found")
    
    # í•­ìƒ ìµœì‹  EPSS/KEV ì •ë³´ ì¡°íšŒ (ìºì‹œ ë¬´ì‹œ)
    from ..core.epss_client import EPSSClient
    from ..core.kev_client import KEVClient
    
    epss_client = EPSSClient()
    kev_client = KEVClient()
    
    # KEV ì´ˆê¸°í™”
    await kev_client.initialize()
    
    # EPSS ì¡°íšŒ (ìºì‹œ ë¬´ì‹œ, ìµœì‹  ë°ì´í„°)
    epss_data = await epss_client.get_epss_score(cve_id)
    if epss_data:
        cve.epss_score = epss_data.get("epss_score")
        cve.epss_percentile = epss_data.get("epss_percentile")
    
    # KEV ì¡°íšŒ
    kev_info = kev_client.get_kev_info(cve_id)
    if kev_info:
        cve.is_kev = True
        cve.kev_date_added = kev_info.get("dateAdded")
        cve.kev_due_date = kev_info.get("dueDate")
        cve.kev_ransomware = kev_info.get("knownRansomwareCampaignUse") == "Known"
    else:
        cve.is_kev = False
    
    # DB ì—…ë°ì´íŠ¸
    await session.commit()
    await session.refresh(cve)
    
    return {
        "cve_id": cve.cve_id,
        "description": cve.description,
        "published_date": cve.published_date.isoformat() if cve.published_date else None,
        "last_modified": cve.last_modified.isoformat() if cve.last_modified else None,
        # CVSS v3
        "cvss_v3_score": cve.cvss_v3_score,
        "cvss_v3_vector": cve.cvss_v3_vector,
        "cvss_v3_severity": cve.cvss_v3_severity,
        # CVSS v2
        "cvss_v2_score": cve.cvss_v2_score,
        "cvss_v2_vector": cve.cvss_v2_vector,
        "cvss_v2_severity": cve.cvss_v2_severity,
        # CVSS v4
        "cvss_v4_score": cve.cvss_v4_score,
        "cvss_v4_vector": cve.cvss_v4_vector,
        "cvss_v4_severity": cve.cvss_v4_severity,
        # CVSS ë©”íŠ¸ë¦­
        "attack_vector": cve.attack_vector,
        "attack_complexity": cve.attack_complexity,
        "privileges_required": cve.privileges_required,
        "user_interaction": cve.user_interaction,
        "scope": cve.scope,
        "confidentiality_impact": cve.confidentiality_impact,
        "integrity_impact": cve.integrity_impact,
        "availability_impact": cve.availability_impact,
        # CPE & References
        "cpe_list": cve.cpe_list,
        "references": cve.references,
        # EPSS (Exploit Prediction Score)
        "epss_score": cve.epss_score,
        "epss_percentile": cve.epss_percentile,
        # KEV (Known Exploited Vulnerabilities)
        "is_kev": cve.is_kev,
        "kev_date_added": cve.kev_date_added,
        "kev_due_date": cve.kev_due_date,
        "kev_ransomware": cve.kev_ransomware,
        # Exploit ì •ë³´
        "has_exploit": cve.has_exploit,
        "exploit_count": cve.exploit_count,
        "exploit_sources": cve.exploit_sources,
        "exploit_urls": cve.exploit_urls
    }


# ==================== Exploit/PoC API ====================

@router.get("/exploit/search/{cve_id}")
async def search_exploit(
    cve_id: str,
    use_cache: bool = Query(True, description="ìºì‹œ ì‚¬ìš© ì—¬ë¶€"),
    session: AsyncSession = Depends(get_db)
):
    """
    CVEì— ëŒ€í•œ Exploit/PoC ì •ë³´ ê²€ìƒ‰
    
    - GitHub PoC (nomi-sec/PoC-in-GitHub)
    - Exploit-DB (searchsploit)
    """
    from ..core.exploit_client import get_exploit_client
    
    client = get_exploit_client()
    result = await client.search_exploits(cve_id, use_cache=use_cache)
    
    # DBì— exploit ì •ë³´ ì—…ë°ì´íŠ¸
    if result.get('has_exploit'):
        try:
            cve_result = await session.execute(
                select(CVE).where(CVE.cve_id == cve_id)
            )
            cve = cve_result.scalar_one_or_none()
            
            if cve:
                cve.has_exploit = True
                cve.exploit_count = result.get('exploit_count', 0)
                
                sources = []
                if result.get('github_pocs'):
                    sources.append('github')
                if result.get('exploitdb'):
                    sources.append('exploitdb')
                cve.exploit_sources = ','.join(sources)
                
                # URL ëª©ë¡ ì €ì¥
                urls = []
                for poc in result.get('github_pocs', [])[:5]:
                    urls.append({'source': 'github', 'url': poc.get('url', '')})
                for exp in result.get('exploitdb', [])[:5]:
                    urls.append({'source': 'exploitdb', 'url': exp.get('url', '')})
                cve.exploit_urls = json.dumps(urls)
                cve.exploit_last_checked = datetime.now(KST)
                
                await session.commit()
        except Exception as e:
            logger.error(f"Failed to update exploit info for {cve_id}: {e}")
    
    return result


@router.post("/exploit/batch-search")
async def batch_search_exploits(
    cve_ids: List[str],
    session: AsyncSession = Depends(get_db)
):
    """ì—¬ëŸ¬ CVEì— ëŒ€í•œ Exploit ì •ë³´ ì¼ê´„ ê²€ìƒ‰"""
    from ..core.exploit_client import get_exploit_client
    
    if len(cve_ids) > 50:
        raise HTTPException(status_code=400, detail="Maximum 50 CVEs per request")
    
    client = get_exploit_client()
    results = await client.batch_search(cve_ids)
    
    # DB ì¼ê´„ ì—…ë°ì´íŠ¸
    updated_count = 0
    for cve_id, result in results.items():
        if result.get('has_exploit'):
            try:
                cve_result = await session.execute(
                    select(CVE).where(CVE.cve_id == cve_id)
                )
                cve = cve_result.scalar_one_or_none()
                
                if cve:
                    cve.has_exploit = True
                    cve.exploit_count = result.get('exploit_count', 0)
                    sources = []
                    if result.get('github_pocs'):
                        sources.append('github')
                    if result.get('exploitdb'):
                        sources.append('exploitdb')
                    cve.exploit_sources = ','.join(sources)
                    cve.exploit_last_checked = datetime.now(KST)
                    updated_count += 1
            except Exception as e:
                logger.error(f"Failed to update {cve_id}: {e}")
    
    await session.commit()
    
    return {
        "total_searched": len(cve_ids),
        "exploits_found": sum(1 for r in results.values() if r.get('has_exploit')),
        "db_updated": updated_count,
        "results": results
    }


@router.get("/exploit/check-tools")
async def check_exploit_tools():
    """PoC ì‹¤í–‰ì— í•„ìš”í•œ ë„êµ¬ ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸"""
    from ..core.exploit_client import get_poc_executor
    
    executor = get_poc_executor()
    tools = executor.check_prerequisites()
    
    recommendations = []
    if not tools.get('searchsploit'):
        recommendations.append("searchsploit: sudo apt install exploitdb")
    if not tools.get('nmap'):
        recommendations.append("nmap: sudo apt install nmap")
    if not tools.get('msfconsole'):
        recommendations.append("metasploit: https://docs.metasploit.com/docs/using-metasploit/getting-started/nightly-installers.html")
    
    return {
        "tools": tools,
        "ready": all(tools.get(t) for t in ['python3', 'nmap', 'curl']),
        "full_ready": all(tools.values()),
        "recommendations": recommendations
    }


class PoCExecuteRequest(BaseModel):
    """PoC ì‹¤í–‰ ìš”ì²­"""
    target_host: str
    target_port: int = 80
    poc_type: str = "nmap_vuln"  # github_poc, metasploit, nmap_vuln, manual
    poc_url: Optional[str] = None
    cve_id: Optional[str] = None
    dry_run: bool = True  # ê¸°ë³¸: dry run (ì‹¤ì œ ì‹¤í–‰ ì•ˆ í•¨)
    confirm: bool = False  # ì‹¤í–‰ í™•ì¸ (dry_run=Falseì¼ ë•Œ í•„ìˆ˜)


@router.post("/exploit/execute")
async def execute_poc(request: PoCExecuteRequest):
    """
    PoC/Exploit ì‹¤í–‰ (ì•ˆì „ ëª¨ë“œ)
    
    âš ï¸ ì£¼ì˜: 
    - ì´ ê¸°ëŠ¥ì€ ë°˜ë“œì‹œ ê¶Œí•œì´ ìˆëŠ” í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œë§Œ ì‚¬ìš©í•˜ì„¸ìš”
    - ê¶Œí•œ ì—†ëŠ” ì‹œìŠ¤í…œì— ëŒ€í•œ ê³µê²©ì€ ë¶ˆë²•ì…ë‹ˆë‹¤
    - dry_run=True (ê¸°ë³¸ê°’)ì€ ëª…ë ¹ì–´ë§Œ ìƒì„±í•˜ê³  ì‹¤í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
    """
    from ..core.exploit_client import get_poc_executor
    
    # ì‹¤ì œ ì‹¤í–‰ ì‹œ í™•ì¸ í•„ìˆ˜
    if not request.dry_run and not request.confirm:
        raise HTTPException(
            status_code=400, 
            detail="ì‹¤ì œ ì‹¤í–‰ì„ ìœ„í•´ì„œëŠ” confirm=Trueê°€ í•„ìš”í•©ë‹ˆë‹¤. ê¶Œí•œ ìˆëŠ” ì‹œìŠ¤í…œì—ì„œë§Œ ì‚¬ìš©í•˜ì„¸ìš”."
        )
    
    # localhost/ë‚´ë¶€ë§ ì²´í¬ (ì™¸ë¶€ ê³µê²© ë°©ì§€)
    import ipaddress
    try:
        ip = ipaddress.ip_address(request.target_host)
        if not request.dry_run and ip.is_global:
            raise HTTPException(
                status_code=403,
                detail="ì™¸ë¶€ IPì— ëŒ€í•œ ì‹¤ì œ ê³µê²©ì€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. dry_run ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
            )
    except ValueError:
        # ë„ë©”ì¸ì¸ ê²½ìš°
        if not request.dry_run and not request.target_host.endswith('.local'):
            raise HTTPException(
                status_code=403,
                detail="ì™¸ë¶€ ë„ë©”ì¸ì— ëŒ€í•œ ì‹¤ì œ ê³µê²©ì€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            )
    
    executor = get_poc_executor()
    result = await executor.execute_poc(
        target_host=request.target_host,
        target_port=request.target_port,
        poc_type=request.poc_type,
        poc_url=request.poc_url or "",
        cve_id=request.cve_id or "",
        dry_run=request.dry_run
    )
    
    return result


@router.get("/exploit/log")
async def get_exploit_execution_log():
    """PoC ì‹¤í–‰ ë¡œê·¸ ì¡°íšŒ"""
    from ..core.exploit_client import get_poc_executor
    
    executor = get_poc_executor()
    return {
        "log": executor.get_execution_log(),
        "total": len(executor.get_execution_log())
    }


# í˜¸ìŠ¤íŠ¸ë³„ exploit ì¡°íšŒ API
@router.get("/hosts/{host_id}/exploits")
async def get_host_exploits(
    host_id: int,
    refresh: bool = Query(False, description="ê°•ì œ ìƒˆë¡œê³ ì¹¨"),
    session: AsyncSession = Depends(get_db)
):
    """í˜¸ìŠ¤íŠ¸ì˜ ì·¨ì•½ì  ì¤‘ Exploitì´ ì¡´ì¬í•˜ëŠ” ê²ƒë“¤ ì¡°íšŒ"""
    from ..core.exploit_client import get_exploit_client
    
    # í˜¸ìŠ¤íŠ¸ì˜ CVE ëª©ë¡ ì¡°íšŒ
    result = await session.execute(
        select(Finding, CVE)
        .join(CVE, Finding.cve_id == CVE.id)
        .where(Finding.host_id == host_id)
    )
    rows = result.all()
    
    if not rows:
        return {"host_id": host_id, "exploits": [], "total": 0}
    
    # CVE ID ëª©ë¡
    cve_ids = list(set(cve.cve_id for _, cve in rows))
    
    # Exploit ì •ë³´ ì¡°íšŒ (refresh ì‹œ ìºì‹œ ë¬´ì‹œ)
    if refresh:
        client = get_exploit_client()
        exploit_results = await client.batch_search(cve_ids[:30])  # ìµœëŒ€ 30ê°œ
    else:
        # DBì—ì„œ ê¸°ì¡´ exploit ì •ë³´ ì‚¬ìš©
        exploit_results = {}
        for _, cve in rows:
            if cve.has_exploit:
                exploit_results[cve.cve_id] = {
                    'cve_id': cve.cve_id,
                    'has_exploit': True,
                    'exploit_count': cve.exploit_count or 0,
                    'exploit_sources': cve.exploit_sources,
                    'exploit_urls': json.loads(cve.exploit_urls) if cve.exploit_urls else []
                }
    
    # Exploitì´ ìˆëŠ” CVEë§Œ í•„í„°ë§
    exploits_with_info = []
    for finding, cve in rows:
        cve_id = cve.cve_id
        if cve_id in exploit_results and exploit_results[cve_id].get('has_exploit'):
            exploits_with_info.append({
                'cve_id': cve_id,
                'cvss_score': cve.cvss_v3_score or cve.cvss_v2_score,
                'is_kev': cve.is_kev,
                'exploit_count': exploit_results[cve_id].get('exploit_count', 0),
                'exploit_sources': exploit_results[cve_id].get('exploit_sources', ''),
                'github_pocs': exploit_results[cve_id].get('github_pocs', [])[:3],
                'exploitdb': exploit_results[cve_id].get('exploitdb', [])[:3],
            })
    
    # CVSS ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    exploits_with_info.sort(key=lambda x: x.get('cvss_score') or 0, reverse=True)
    
    return {
        "host_id": host_id,
        "total_cves": len(cve_ids),
        "exploits_found": len(exploits_with_info),
        "exploits": exploits_with_info
    }


@router.post("/exploit/refresh-csv")
async def refresh_exploitdb_csv():
    """
    Exploit-DB CSV ìºì‹œ ê°•ì œ ê°±ì‹ 
    
    GitLabì—ì„œ ìµœì‹  CSV íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë©”ëª¨ë¦¬ ìºì‹œë¥¼ ê°±ì‹ í•©ë‹ˆë‹¤.
    ì •ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ìµœì‹  Exploit ì •ë³´ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    from ..core.exploit_client import get_exploit_client
    
    client = get_exploit_client()
    
    # ê¸°ì¡´ ìºì‹œ ì •ë³´
    old_count = len(client.exploitdb_csv_cache)
    old_timestamp = client.exploitdb_csv_timestamp
    
    # CSV ê°•ì œ ê°±ì‹ 
    success = await client._load_exploitdb_csv(force_refresh=True)
    
    if not success:
        raise HTTPException(status_code=500, detail="Failed to refresh Exploit-DB CSV")
    
    new_count = len(client.exploitdb_csv_cache)
    new_timestamp = client.exploitdb_csv_timestamp
    
    return {
        "status": "success",
        "message": "Exploit-DB CSV refreshed successfully",
        "old_cache": {
            "cve_count": old_count,
            "timestamp": old_timestamp
        },
        "new_cache": {
            "cve_count": new_count,
            "timestamp": new_timestamp
        },
        "diff": new_count - old_count
    }


@router.get("/exploit/csv-status")
async def get_exploitdb_csv_status():
    """
    Exploit-DB CSV ìºì‹œ ìƒíƒœ ì¡°íšŒ
    
    í˜„ì¬ ë©”ëª¨ë¦¬ì— ë¡œë“œëœ CSV ìºì‹œì˜ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    from ..core.exploit_client import get_exploit_client
    
    client = get_exploit_client()
    
    if not client.exploitdb_csv_cache or not client.exploitdb_csv_timestamp:
        return {
            "status": "not_loaded",
            "message": "CSV cache not loaded. It will be loaded automatically on first search.",
            "cve_count": 0,
            "timestamp": None
        }
    
    # ìºì‹œ ë‚˜ì´ ê³„ì‚°
    from datetime import datetime
    age = datetime.now() - client.exploitdb_csv_timestamp
    age_hours = age.total_seconds() / 3600
    
    # ë§Œë£Œ ì—¬ë¶€
    is_expired = age_hours >= client.exploitdb_csv_ttl_hours
    
    return {
        "status": "loaded",
        "cve_count": len(client.exploitdb_csv_cache),
        "timestamp": client.exploitdb_csv_timestamp,
        "age_hours": round(age_hours, 1),
        "ttl_hours": client.exploitdb_csv_ttl_hours,
        "is_expired": is_expired,
        "message": "CSV cache is up-to-date" if not is_expired else "CSV cache expired, will refresh on next search"
    }

